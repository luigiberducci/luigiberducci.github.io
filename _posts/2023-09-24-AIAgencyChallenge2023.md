---
layout: post
title: Celebrating Collaboration, Our Win at the AI Agency Hackathon
subtitle: Our work on agency-preserving RL under partial-observable intentions wins the AI Agency Hackaton!
cover-img: /assets/img/ai_safety_hackathon.png
thumbnail-img: /assets/img/ai_safety_hackathon.png
share-img: /assets/img/ai_safety_hackathon.png
tags: [ai-safety, agency-preserving rl, reinforcement learning, altruistic agents]
---

On behalf of my fantastic co-author Harry Powell, I am happy to announce that our project:

**Preserving Agency in Reinforcement Learning under Unknown, Evolving and Under-Represented Intentions**
*Luigi Berducci & Harry Powell.*

won the first place at the [AI Agency Hackathon](https://alignmentjam.com/jam/agency)!

Starting from a **simple idea** of training **altruistic agents** under **partial observability** and 
**unequal distribution** of **values**,
we developed a project over **few days**.

Despite the limited time and preliminary status of the results :alarm_clock:,
it has been a **great and very fun experience** that I want to share with you! :smile: :sunglasses:

**Abstract**:
This paper investigates several techniques to implement altruistic RL while preserving agency. 
Using a two-player grid game, we train a helper agent to support a lead agent in achieving their goals. 
By training the helper without showing them the goal and resampling the goals to rebalance for 
unequal value distributions, we demonstrate that helpers can act altruistically without observing 
the goals of the lead. We also initiate exploration of a technique to encourage corrigibility and 
respect for personal agency by resampling the leads values during training time, and point towards 
how these techniques could be used to translate into real-world situations through meta-learning.


[Report](https://alignmentjam.com/project/preserving-agency-in-reinforcement-learning-under-unknown-evolving-and-under-represented-intentions)

[Code](https://github.com/luigiberducci/agency_hackaton)

[Video - Coming soon]()

